import os
from fastapi import FastAPI, HTTPException
from fastapi.responses import FileResponse
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain_community.embeddings import HuggingFaceEmbeddings  # ë¬´ë£Œ ë¡œì»¬ ì„ë² ë”©!
from typing import List, Optional

app = FastAPI()

# 1. CORS ì„¤ì • (ë¦¬ì•¡íŠ¸ì™€ í†µì‹  í—ˆìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# â˜…â˜…â˜… ì—¬ê¸°ì— êµ¬ê¸€ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš” â˜…â˜…â˜…
os.environ["GOOGLE_API_KEY"] = "AIzaSyAhJ5ZXG8vnnkECvkuXk6mlCrYh5OCY3VQ"

# ì „ì—­ ë³€ìˆ˜
vectorstore = None
loaded_documents_info = []  # PDF ë©”íƒ€ë°ì´í„° ì €ì¥

# PDF íŒŒì¼ëª…ì—ì„œ êµ­ê°€ì™€ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ í•¨ìˆ˜
def extract_metadata(filename):
    """íŒŒì¼ëª…ì—ì„œ êµ­ê°€ì™€ ì¹´í…Œê³ ë¦¬ë¥¼ ìŠ¤ë§ˆíŠ¸í•˜ê²Œ ì¶”ì¶œ"""
    filename_lower = filename.lower()
    
    # êµ­ê°€ ê°ì§€
    if "canada" in filename_lower:
        country = "Canada"
    elif "france" in filename_lower or "franÃ§aise" in filename_lower or "snbc" in filename_lower or "carbone" in filename_lower:
        country = "France"
    elif "germany" in filename_lower or "klima" in filename_lower or "german" in filename_lower:
        country = "Germany"
    elif "african" in filename_lower or "afdb" in filename_lower:
        country = "Africa"
    elif "un " in filename_lower or "global" in filename_lower or "ndc" in filename_lower:
        country = "Global"
    else:
        country = "Global"
    
    # ì¹´í…Œê³ ë¦¬ ê°ì§€
    if "agri" in filename_lower or "food" in filename_lower:
        category = "Agriculture"
    elif "energy" in filename_lower or "grid" in filename_lower or "renewable" in filename_lower:
        category = "Energy"
    elif "emission" in filename_lower or "carbon" in filename_lower or "climate" in filename_lower or "klima" in filename_lower:
        category = "Climate"
    elif "health" in filename_lower:
        category = "Health"
    elif "supply" in filename_lower or "logistics" in filename_lower:
        category = "Supply Chain"
    else:
        category = "Policy"
    
    # ë¬¸ì„œ íƒ€ì… ê°ì§€
    if "report" in filename_lower:
        doc_type = "Report"
    elif "plan" in filename_lower or "strategy" in filename_lower or "strategie" in filename_lower:
        doc_type = "Strategy"
    elif "brief" in filename_lower:
        doc_type = "Brief"
    elif "act" in filename_lower or "law" in filename_lower:
        doc_type = "Legislation"
    else:
        doc_type = "Document"
    
    # ë…„ë„ ì¶”ì¶œ ì‹œë„
    import re
    year_match = re.search(r'20\d{2}', filename)
    year = year_match.group() if year_match else "2023"
    
    return country, category, doc_type, year

# 2. PDF ë¡œë“œ ë° ë©”íƒ€ë°ì´í„° íƒœê¹… í•¨ìˆ˜
def load_and_tag_documents():
    global vectorstore, loaded_documents_info
    documents = []
    loaded_documents_info = []  # ì´ˆê¸°í™”
    
    # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
    data_folder = os.path.join(os.path.dirname(os.path.abspath(__file__)), "data")
    
    # í´ë” ì—†ìœ¼ë©´ ìƒì„±
    if not os.path.exists(data_folder):
        os.makedirs(data_folder)
        print("ğŸ“ 'data' í´ë”ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. PDF íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")
        return

    print("ğŸ”„ PDF ë¡œë”© ë° íƒœê·¸ ë¶„ì„ ì‹œì‘...")
    
    files = [f for f in os.listdir(data_folder) if f.endswith(".pdf")]
    
    if not files:
        print("âš ï¸ data í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ëª¨ë“  íŒŒì¼ ë¡œë“œ (ë¡œì»¬ ì„ë² ë”© ì‚¬ìš©í•˜ë¯€ë¡œ í• ë‹¹ëŸ‰ ê±±ì • ì—†ìŒ)
    print(f"ğŸ“„ ì´ {len(files)}ê°œ PDF íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.")

    for idx, filename in enumerate(files):
        # ìŠ¤ë§ˆíŠ¸ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        country_tag, category_tag, doc_type, year = extract_metadata(filename)
        
        try:
            loader = PyPDFLoader(os.path.join(data_folder, filename))
            docs = loader.load()
            
            # ì²« í˜ì´ì§€ì—ì„œ excerpt ì¶”ì¶œ
            excerpt = docs[0].page_content[:200] + "..." if docs else "No content available."
            
            # ì½ì€ ë¬¸ì„œì— íƒœê·¸(ê¼¬ë¦¬í‘œ) ë‹¬ê¸°
            for doc in docs:
                doc.metadata["country"] = country_tag
                doc.metadata["category"] = category_tag
                doc.metadata["source"] = filename
            
            documents.extend(docs)
            
            # ë¬¸ì„œ ì •ë³´ ì €ì¥ (í”„ë¡ íŠ¸ì—”ë“œìš©)
            loaded_documents_info.append({
                "id": f"DOC-{idx+1:03d}",
                "filename": filename,
                "title": filename.replace(".pdf", "").replace("-", " ").replace("_", " "),
                "country": country_tag,
                "category": category_tag,
                "type": doc_type,
                "year": year,
                "pages": len(docs),
                "excerpt": excerpt
            })
            
            print(f"   ğŸ‘‰ ë¡œë“œ ì„±ê³µ: {filename} -> [êµ­ê°€:{country_tag}, ì¹´í…Œê³ ë¦¬:{category_tag}]")
        except Exception as e:
            print(f"   âŒ ë¡œë“œ ì‹¤íŒ¨ ({filename}): {e}")

    # ë¬¸ì„œê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ DB êµ¬ì¶•
    if documents:
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(documents)
        
        # ë¬´ë£Œ ë¡œì»¬ ì„ë² ë”© (HuggingFace) - API í• ë‹¹ëŸ‰ ê±±ì • ì—†ìŒ!
        print("ğŸ”„ ë¡œì»¬ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘ (ì²˜ìŒì—” ë‹¤ìš´ë¡œë“œë¡œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŒ)...")
        embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
        # ChromaDBì— ì €ì¥
        vectorstore = Chroma.from_documents(splits, embeddings)
        print(f"âœ… ì´ {len(documents)} í˜ì´ì§€, {len(loaded_documents_info)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ. RAG ì¤€ë¹„ ë!")
    else:
        print("âš ï¸ ë¡œë“œëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

# 3. ìš”ì²­ ë°ì´í„° ëª¨ë¸
class ChatRequest(BaseModel):
    query: str
    country: str = "Global"
    scenario: str = "General"

class InsightRequest(BaseModel):
    """AI Strategic Briefingìš© ì¸ì‚¬ì´íŠ¸ ìš”ì²­"""
    country: str = "Canada"
    scenario: str = "Health"  # Agri, Energy, Supply, Health
    weather_data: dict = {}   # í˜„ì¬ ê¸°ìƒ ë°ì´í„°

# [ìƒˆë¡œìš´ í•µì‹¬ API] AI-Driven Insight ìƒì„±
@app.post("/insight")
def generate_insight(req: InsightRequest):
    """
    í˜„ì¬ ê¸°ìƒ ë°ì´í„° + RAG ë¬¸ì„œ ê²€ìƒ‰ â†’ LLMì´ ì •ì±… ì¸ì‚¬ì´íŠ¸ ìƒì„±
    """
    global vectorstore
    
    if not vectorstore:
        return {
            "insight": "ì •ì±… ë¬¸ì„œê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "signal": "N/A",
            "status": "ERROR",
            "action": "ì„œë²„ë¥¼ ì¬ì‹œì‘í•˜ì„¸ìš”",
            "sources": [],
            "key_points": []
        }
    
    # ì‹œë‚˜ë¦¬ì˜¤ë³„ ê²€ìƒ‰ ì¿¼ë¦¬ ë° ë¶„ì„ í¬ì¸íŠ¸ ì„¤ì •
    scenario_config = {
        "Agri": {
            "search_query": f"agriculture climate policy soil moisture drought food security {req.country}",
            "signal_key": "soilMoisture",
            "signal_format": lambda d: f"Soil Moisture: {(d.get('soilMoisture', 0.3) * 100):.1f}%",
            "focus": "ë†ì—… ì •ì±…, ê°€ë­„ ëŒ€ì‘, ì‹ëŸ‰ ì•ˆë³´"
        },
        "Energy": {
            "search_query": f"energy policy renewable solar wind grid climate {req.country}",
            "signal_key": "solarRad",
            "signal_format": lambda d: f"Solar Radiation: {d.get('solarRad', 0):.1f} MJ/mÂ²",
            "focus": "ì—ë„ˆì§€ ì „í™˜, ì¬ìƒì—ë„ˆì§€, íƒ„ì†Œ ë°°ì¶œ"
        },
        "Supply": {
            "search_query": f"supply chain logistics climate risk port infrastructure {req.country}",
            "signal_key": "gust",
            "signal_format": lambda d: f"Wind Gusts: {d.get('gust', 0):.1f} km/h",
            "focus": "ë¬¼ë¥˜ ë¦¬ìŠ¤í¬, ê³µê¸‰ë§ ë³µì›ë ¥, ì¸í”„ë¼"
        },
        "Health": {
            "search_query": f"public health climate heat wave cold weather policy {req.country}",
            "signal_key": "feelTemp",
            "signal_format": lambda d: f"Apparent Temp: {d.get('feelTemp', 0):.1f}Â°C",
            "focus": "ê³µì¤‘ ë³´ê±´, ê¸°ì˜¨ ê·¹í•œ ëŒ€ì‘, ì·¨ì•½ê³„ì¸µ ë³´í˜¸"
        }
    }
    
    config = scenario_config.get(req.scenario, scenario_config["Health"])
    weather = req.weather_data or {}
    
    # RAG ê²€ìƒ‰ ì‹¤í–‰
    search_kwargs = {
        "k": 5,
        "filter": {
            "$or": [
                {"country": req.country},
                {"country": "Global"}
            ]
        }
    }
    
    try:
        # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        retriever = vectorstore.as_retriever(search_kwargs=search_kwargs)
        relevant_docs = retriever.get_relevant_documents(config["search_query"])
        
        # ë¬¸ì„œ ë‚´ìš© ì¶”ì¶œ
        context_text = "\n\n---\n\n".join([
            f"[ì¶œì²˜: {doc.metadata.get('source', 'Unknown')}]\n{doc.page_content[:800]}"
            for doc in relevant_docs[:4]
        ])
        
        sources = list(set([doc.metadata.get('source', 'Unknown') for doc in relevant_docs]))
        
        # LLMìœ¼ë¡œ ì¸ì‚¬ì´íŠ¸ ìƒì„± (gemini-2.0-flash ì‚¬ìš©)
        llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash")
        
        prompt = f"""ë‹¹ì‹ ì€ G7 ê¸°í›„ ì •ì±… ë¶„ì„ AIì…ë‹ˆë‹¤.

## í˜„ì¬ ìƒí™©
- êµ­ê°€: {req.country}
- ë¶„ì„ ì‹œë‚˜ë¦¬ì˜¤: {req.scenario} ({config['focus']})
- í˜„ì¬ ê¸°ìƒ ë°ì´í„°: 
  * ì²´ê°ì˜¨ë„: {weather.get('feelTemp', 'N/A')}Â°C
  * ì‹¤ì œì˜¨ë„: {weather.get('realTemp', 'N/A')}Â°C
  * í† ì–‘ìˆ˜ë¶„: {(weather.get('soilMoisture', 0.3) * 100):.1f}%
  * ê°•ìˆ˜ëŸ‰: {weather.get('rain', 0)}mm
  * íƒœì–‘ë³µì‚¬ëŸ‰: {weather.get('solarRad', 0)} MJ/mÂ²
  * ëŒí’: {weather.get('gust', 0)} km/h
  * ì ì„¤ëŸ‰: {weather.get('snow', 0)}cm

## ì°¸ê³  ì •ì±… ë¬¸ì„œ (RAG ê²€ìƒ‰ ê²°ê³¼)
{context_text}

## ìš”ì²­
ìœ„ ì •ì±… ë¬¸ì„œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ, í˜„ì¬ {req.country}ì˜ ê¸°ìƒ ìƒí™©ì— ëŒ€í•œ **ì •ì±…ì  ì¸ì‚¬ì´íŠ¸**ë¥¼ ì œê³µí•˜ì„¸ìš”.

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSON ì‘ë‹µí•˜ì„¸ìš”:
{{
  "status": "ALERT ë˜ëŠ” CAUTION ë˜ëŠ” STABLE ë˜ëŠ” OPTIMAL",
  "headline": "í•µì‹¬ ì¸ì‚¬ì´íŠ¸ í•œ ì¤„ (í•œêµ­ì–´)",
  "analysis": "í˜„ì¬ ê¸°ìƒ ë°ì´í„°ì™€ ì •ì±… ë¬¸ì„œë¥¼ ì—°ê²°í•œ ë¶„ì„ (3-4ë¬¸ì¥, í•œêµ­ì–´)",
  "action": "ê¶Œê³  ì¡°ì¹˜ (í•œêµ­ì–´)",
  "key_points": ["í•µì‹¬ í¬ì¸íŠ¸ 1", "í•µì‹¬ í¬ì¸íŠ¸ 2", "í•µì‹¬ í¬ì¸íŠ¸ 3"],
  "policy_relevance": "ì–´ë–¤ ì •ì±… ë¬¸ì„œê°€ ì™œ ê´€ë ¨ ìˆëŠ”ì§€ ì„¤ëª… (í•œêµ­ì–´)"
}}

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´.
"""
        
        response = llm.invoke(prompt)
        response_text = response.content.strip()
        
        # JSON íŒŒì‹± ì‹œë„
        import json
        import re
        
        # JSON ë¸”ë¡ ì¶”ì¶œ
        json_match = re.search(r'\{[\s\S]*\}', response_text)
        if json_match:
            insight_data = json.loads(json_match.group())
        else:
            insight_data = {
                "status": "STABLE",
                "headline": "ë¶„ì„ ì¤‘...",
                "analysis": response_text[:300],
                "action": "ëª¨ë‹ˆí„°ë§ ì§€ì†",
                "key_points": [],
                "policy_relevance": ""
            }
        
        return {
            "signal": config["signal_format"](weather),
            "status": insight_data.get("status", "STABLE"),
            "headline": insight_data.get("headline", ""),
            "analysis": insight_data.get("analysis", ""),
            "action": insight_data.get("action", ""),
            "key_points": insight_data.get("key_points", []),
            "policy_relevance": insight_data.get("policy_relevance", ""),
            "sources": sources,
            "scenario": req.scenario,
            "country": req.country
        }
        
    except Exception as e:
        print(f"Insight generation error: {e}")
        return {
            "signal": config["signal_format"](weather),
            "status": "ERROR",
            "headline": "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
            "analysis": str(e),
            "action": "ì‹œìŠ¤í…œ í™•ì¸ í•„ìš”",
            "key_points": [],
            "sources": [],
            "scenario": req.scenario,
            "country": req.country
        }

# 4. ì±„íŒ… API (ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì ìš©)
@app.post("/chat")
def chat(req: ChatRequest):
    global vectorstore
    
    # DBê°€ ë¹„ì–´ìˆìœ¼ë©´ ì•ˆë‚´ ë©”ì‹œì§€ ë°˜í™˜
    if not vectorstore:
        return {
            "answer": "ì„œë²„ì— ë¡œë“œëœ ì •ì±… ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. backend/data í´ë”ì— PDFë¥¼ ë„£ê³  ì„œë²„ë¥¼ ì¬ì‹œì‘í•´ì£¼ì„¸ìš”.",
            "sources": []
        }
    
    # [í•µì‹¬] ê²€ìƒ‰ í•„í„°: ë‚´ êµ­ê°€ ë¬¸ì„œ OR ê¸€ë¡œë²Œ ë¬¸ì„œë§Œ ì°¾ê¸°
    search_kwargs = {
        "k": 4, # ìƒìœ„ 4ê°œ ë¬¸ì„œ ì°¸ì¡°
        "filter": {
            "$or": [
                {"country": req.country}, # ì„ íƒí•œ êµ­ê°€ (ì˜ˆ: Canada)
                {"country": "Global"}     # ë˜ëŠ” ê³µí†µ ë¬¸ì„œ
            ]
        }
    }
    
    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash")
    
    # í”„ë¡¬í”„íŠ¸: í•œêµ­ì–´ë¡œ ì „ë¬¸ì ì¸ ë‹µë³€ ìœ ë„
    template = f"""
    ë‹¹ì‹ ì€ G7 ì •ì±… ë³´ì¢Œê´€ì…ë‹ˆë‹¤.
    í˜„ì¬ '{req.country}' êµ­ê°€ì˜ '{req.scenario}' ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤.
    ì œê³µëœ ë¬¸ë§¥(Context)ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•´ í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
    ë¬¸ë§¥ì— ì—†ëŠ” ë‚´ìš©ì€ ì§€ì–´ë‚´ì§€ ë§ê³  ëª¨ë¥¸ë‹¤ê³  í•˜ì„¸ìš”.
    
    Context: {{context}}
    
    Question: {{question}}
    
    Answer (Korean):
    """
    PROMPT = PromptTemplate.from_template(template)

    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=vectorstore.as_retriever(search_kwargs=search_kwargs),
        return_source_documents=True,
        chain_type_kwargs={"prompt": PROMPT}
    )
    
    try:
        # ì§ˆë¬¸ ë˜ì§€ê¸°
        result = qa_chain.invoke({"query": req.query})
        
        # ì°¸ê³ í•œ ë¬¸ì„œ ì¶œì²˜ ëª©ë¡ ë§Œë“¤ê¸°
        sources = list(set([doc.metadata['source'] for doc in result['source_documents']]))
        
        return {
            "answer": result['result'],
            "sources": sources
        }
    except Exception as e:
        return {
            "answer": f"ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", 
            "sources": []
        }

# 5. ë¬¸ì„œ ëª©ë¡ API - Policy Libraryìš©
@app.get("/documents")
def get_documents():
    """Policy Libraryì—ì„œ ì‚¬ìš©í•  ë¬¸ì„œ ëª©ë¡ ë°˜í™˜"""
    return {"documents": loaded_documents_info}

# 6. PDF íŒŒì¼ ì„œë¹™ - View Documentìš©
@app.get("/pdf/{filename:path}")
def get_pdf(filename: str):
    """PDF íŒŒì¼ì„ ë¸Œë¼ìš°ì €ì—ì„œ ë³¼ ìˆ˜ ìˆë„ë¡ ì„œë¹™"""
    pdf_folder = os.path.join(os.path.dirname(os.path.abspath(__file__)), "data")
    file_path = os.path.join(pdf_folder, filename)
    if os.path.exists(file_path):
        return FileResponse(file_path, media_type="application/pdf", filename=filename)
    return {"error": "File not found"}

# ì„œë²„ ì¼œì§ˆ ë•Œ ì‹¤í–‰
@app.on_event("startup")
def startup():
    load_and_tag_documents()

if __name__ == "__main__":
    import uvicorn
    # 0.0.0.0ìœ¼ë¡œ ì—´ì–´ì„œ ì™¸ë¶€ ì ‘ì† í—ˆìš©
    uvicorn.run(app, host="0.0.0.0", port=8000)
